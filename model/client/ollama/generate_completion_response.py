"""
    Assistance Backbone for the assistance system developed as part of the VerDatAs project
    Copyright (C) 2022-2024 TU Dresden (Robert Schmidt)

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with this program.  If not, see <http://www.gnu.org/licenses/>.
"""

"""
    Ollama API

    API Spec for Ollama API. Please see https://github.com/jmorganca/ollama/blob/main/docs/api.md for more details.

    The version of the OpenAPI document: 0.1.9
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501

from __future__ import annotations

import json
import pprint
import re  # noqa: F401
from datetime import datetime
from typing import Any, ClassVar, Dict, List, Optional

from pydantic import BaseModel, Field, StrictBool, StrictInt, StrictStr

try:
    from typing import Self
except ImportError:
    from typing_extensions import Self


class GenerateCompletionResponse(BaseModel):
    """
    The response class for the generate endpoint.
    """  # noqa: E501
    model: Optional[StrictStr] = Field(default=None,
                                       description="The model name.  Model names follow a `model:tag` format. Some examples are `orca-mini:3b-q4_1` and `llama2:70b`. The tag is optional and, if not provided, will default to `latest`. The tag is used to identify a specific version. ")
    created_at: Optional[datetime] = Field(default=None, description="Date on which a model was created.")
    response: Optional[StrictStr] = Field(default=None,
                                          description="The response for a given prompt with a provided model.")
    done: Optional[StrictBool] = Field(default=None, description="Whether the response has completed.")
    context: Optional[List[StrictInt]] = Field(default=None,
                                               description="An encoding of the conversation used in this response, this can be sent in the next request to keep a conversational memory. ")
    total_duration: Optional[StrictInt] = Field(default=None, description="Time spent generating the response.")
    load_duration: Optional[StrictInt] = Field(default=None, description="Time spent in nanoseconds loading the model.")
    prompt_eval_count: Optional[StrictInt] = Field(default=None, description="Number of tokens in the prompt.")
    prompt_eval_duration: Optional[StrictInt] = Field(default=None,
                                                      description="Time spent in nanoseconds evaluating the prompt.")
    eval_count: Optional[StrictInt] = Field(default=None, description="Number of tokens the response.")
    eval_duration: Optional[StrictInt] = Field(default=None,
                                               description="Time in nanoseconds spent generating the response.")
    __properties: ClassVar[List[str]] = ["model", "created_at", "response", "done", "context", "total_duration",
                                         "load_duration", "prompt_eval_count", "prompt_eval_duration", "eval_count",
                                         "eval_duration"]

    model_config = {
        "populate_by_name": True,
        "validate_assignment": True,
        "protected_namespaces": (),
    }

    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Self:
        """Create an instance of GenerateCompletionResponse from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        _dict = self.model_dump(
            by_alias=True,
            exclude={
            },
            exclude_none=True,
        )
        return _dict

    @classmethod
    def from_dict(cls, obj: Dict) -> Self:
        """Create an instance of GenerateCompletionResponse from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "model": obj.get("model"),
            "created_at": obj.get("created_at"),
            "response": obj.get("response"),
            "done": obj.get("done"),
            "context": obj.get("context"),
            "total_duration": obj.get("total_duration"),
            "load_duration": obj.get("load_duration"),
            "prompt_eval_count": obj.get("prompt_eval_count"),
            "prompt_eval_duration": obj.get("prompt_eval_duration"),
            "eval_count": obj.get("eval_count"),
            "eval_duration": obj.get("eval_duration")
        })
        return _obj
